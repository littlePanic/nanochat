{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e05d0ce-4df3-419c-834e-ca8207623b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a035be-2911-4c90-b714-1125e3c46eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"littlePanic99/nanochat\"\n",
    "\n",
    "base_filename = \"base/d20/model_021400.pt\"\n",
    "mid_filename = \"mid/d20/model_000809.pt\"\n",
    "sft_filename = \"sft/d20/model_000700.pt\"\n",
    "tokenizer_filename = \"tokenizer/latest/tokenizer.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c4377d-076f-49ba-8ba6-c309564ca310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a975437f-e427-4792-89aa-acbec432e3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rjbiggs/rjbiggs99/projects/nanochat/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "with open(hf_hub_download(repo_id=repo_id, filename=tokenizer_filename, local_files_only=True), \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "def token_str(enc, tid: int):\n",
    "    return enc.decode_bytes([tid]).decode(\"utf-8\", errors=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd1b351b-6ef1-4897-b76f-2720d32a7a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "def to_f32_cpu(x):\n",
    "    return x.detach().cpu().float()\n",
    "\n",
    "def center_inplace(x):\n",
    "    x -= x.mean(dim=0, keepdim=True)\n",
    "    return x\n",
    "\n",
    "def l2_normalize_inplace(x, eps=1e-12):\n",
    "    x /= (x.norm(dim=1, keepdim=True) + eps)\n",
    "    return x\n",
    "\n",
    "def fast_cluster_embedding_ids(X, k=256, batch_size=2048, seed=0):\n",
    "    \"\"\"\n",
    "    X: (n, d) L2-normalized torch tensor on CPU\n",
    "    returns: dict {cluster_id: [indices]}\n",
    "    \"\"\"\n",
    "    if torch.is_tensor(X):\n",
    "        X = X.numpy()\n",
    "\n",
    "    km = MiniBatchKMeans(\n",
    "        n_clusters=k,\n",
    "        batch_size=batch_size,\n",
    "        n_init=\"auto\",\n",
    "        random_state=seed,\n",
    "    )\n",
    "\n",
    "    labels = km.fit_predict(X)\n",
    "\n",
    "    clusters = {}\n",
    "    for i, c in enumerate(labels):\n",
    "        clusters.setdefault(c, []).append(i)\n",
    "\n",
    "    return clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042b111b-fefb-4b48-a61b-ee1bed8adc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "\n",
    "def get_E(repo_id=\"littlePanic99/nanochat\", filename=\"base/d20/model_021400.pt\"):\n",
    "    ckpt = hf_hub_download(repo_id=repo_id, filename=filename, local_files_only=True)\n",
    "    emb = torch.load(ckpt, map_location=\"cpu\")[\"transformer.wte.weight\"]\n",
    "    return emb.detach()\n",
    "\n",
    "E = get_E()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3cfe845-9f67-4c13-8d58-b36673d556fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1943,  2.1562, -0.1719,  ...,  0.9688,  1.1016,  0.4277],\n",
       "        [-1.0938,  0.5820, -0.2734,  ...,  0.4004,  0.2402,  1.1328],\n",
       "        [ 0.4902,  0.5078,  0.6445,  ...,  1.3047, -1.5547,  0.5508],\n",
       "        ...,\n",
       "        [-0.1289, -0.7031,  0.0728,  ..., -0.7383,  0.7812, -0.0806],\n",
       "        [ 0.7812, -0.6992,  0.4043,  ...,  0.1426, -0.7656, -0.2656],\n",
       "        [-0.7812,  0.9258,  0.9727,  ..., -0.4609, -0.3008, -1.3125]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dd09b2f-861f-42af-9991-3ade4ff5ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xu = l2_normalize_inplace(center_inplace(to_f32_cpu(E)))\n",
    "clusters = fast_cluster_embedding_ids(Xu, k=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5683f6e4-6212-4156-8bef-5255e952c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_titles = {\n",
    "  195: \"titles_honorifics_degrees\",\n",
    "  248: \"abbreviations_acronyms_misc\",\n",
    "  253: \"name_fragments_foreign\",\n",
    "  230: \"academic_historical_disciplines\",\n",
    "  99: \"latin_prefixes_processes\",\n",
    "  201: \"name_prefixes_particles\",\n",
    "  252: \"proper_nouns_places_ethnic\",\n",
    "  193: \"prepositions_function_words\",\n",
    "  82: \"syllables_interjections\",\n",
    "  165: \"latin_roots_scientific_terms\",\n",
    "  172: \"adjectives_general_descriptors\",\n",
    "  146: \"countries_world_regions\",\n",
    "  243: \"institutional_process_terms\",\n",
    "  211: \"discourse_adverbs\",\n",
    "  7: \"institutions_organizations\",\n",
    "  32: \"given_names_short_forms\",\n",
    "  123: \"historical_religious_adjectives\",\n",
    "  202: \"generic_nouns_collections\",\n",
    "  242: \"common_verbs_actions\",\n",
    "  62: \"common_nouns_objects\",\n",
    "  4: \"surnames_family_names\",\n",
    "  182: \"nationalities_languages\",\n",
    "  160: \"acronyms_universities_agencies\",\n",
    "  36: \"given_names_formal\",\n",
    "  28: \"short_nouns_onomatopoeia\",\n",
    "  113: \"gerunds_process_verbs\",\n",
    "  207: \"cities_states_places\",\n",
    "  143: \"subword_suffixes_fragments\",\n",
    "  209: \"ancient_historical_figures\",\n",
    "  84: \"south_asia_india_culture\",\n",
    "  149: \"ethnic_groups_regions_global\",\n",
    "  184: \"uk_aus_places_regions\",\n",
    "  222: \"milk\",\n",
    "  128: \"given_names_modern\",\n",
    "  78: \"religions_islam_judaism\",\n",
    "  192: \"internet\",\n",
    "  138: \"international_organizations\",\n",
    "  185: \"female_given_names_titles\",\n",
    "  45: \"astronomy_disasters_events\",\n",
    "  116: \"mesopotamia_ancient_near_east\",\n",
    "  237: \"technology_brands_internet\",\n",
    "  34: \"famous_people_figures\",\n",
    "  93: \"surnames_place_based\",\n",
    "  71: \"surname_singleton\",\n",
    "  157: \"female_given_names_modern\",\n",
    "  47: \"virtual_reality\",\n",
    "  80: \"ethnic_conflict_groups\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5abe9faf-0d8a-4929-aed5-88fb8bc14d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def mean_embedding(E: torch.Tensor, ids) -> torch.Tensor:\n",
    "    ids = torch.as_tensor(ids, device=E.device)\n",
    "    return E.index_select(0, ids).mean(dim=0)\n",
    "\n",
    "\n",
    "def cluster_quality(E: torch.Tensor, ids):\n",
    "    X = E[ids]\n",
    "    X = F.normalize(X, dim=1)\n",
    "    c = F.normalize(X.mean(dim=0), dim=0)\n",
    "\n",
    "    cos = X @ c\n",
    "    return {\n",
    "        \"n\": X.shape[0],\n",
    "        \"cos_mean\": cos.mean().item(),\n",
    "        \"cos_min\": cos.min().item(),\n",
    "        \"cos_max\": cos.max().item(),\n",
    "        \"cos_std\": cos.std(unbiased=False).item(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b93df31e-c4bd-43d9-b8b4-791d75f2abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_groups = []\n",
    "\n",
    "\n",
    "for cluster_id, ids in clusters.items():\n",
    "    tokens = [token_str(tokenizer, tid).strip() for tid in ids]\n",
    "    pct_start_upper = len([t for t in  tokens if len(t) > 1 and t[0].isupper()])/len(tokens)\n",
    "    \n",
    "    reference_groups.append({\n",
    "        \"cluster_id\": cluster_id,\n",
    "        \"ids\": ids,\n",
    "        \"tokens\": tokens,\n",
    "        \"title\": cluster_titles.get(cluster_id),\n",
    "        \"embedding\": mean_embedding(E, ids),\n",
    "        \"cluster_quality\": cluster_quality(E, ids),\n",
    "        \"probable_reference\": len(ids) > 3 and pct_start_upper > 0.5,\n",
    "        \"pct_start_upper\": pct_start_upper\n",
    "    })        \n",
    "\n",
    "# reference_groups = sorted(reference_groups, key=lambda g: g[\"cluster_quality\"][\"cos_max\"])\n",
    "reference_groups = sorted(reference_groups, key=lambda g: -g[\"pct_start_upper\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cde2af14-9ed1-47c4-aab6-d11a8f39e4a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.887  0.000  1.000  surname_singleton                Hart, Hart\n",
      "0.891  0.000  1.000  virtual_reality                  VR, VR\n",
      "1.000  0.000  1.000  None                             Roma\n",
      "0.906  0.002  1.000  None                             Sounds, Sounds\n",
      "1.000  0.000  1.000  None                             Disclaimer\n",
      "1.000  0.000  1.000  None                             Shap\n",
      "1.000  0.000  1.000  None                             Raja\n",
      "1.000  0.000  1.000  None                             Yoruba\n",
      "0.996  0.000  1.000  None                             Engl\n",
      "1.000  0.000  1.000  None                             Matilda\n",
      "1.000  0.000  1.000  None                             Experienced\n",
      "1.000  0.000  1.000  None                             Charon\n",
      "1.000  0.000  1.000  None                             IMS\n",
      "1.000  0.000  1.000  None                             Simplified\n",
      "0.410  0.039  0.992  subword_suffixes_fragments       IN, IS, ON, AS, HE, RE, IS, RO, VID, ION\n",
      "0.379  0.037  0.991  common_nouns_objects             atch, Act, Count, Plan, Net, Air, ault, Work, Press, Port\n",
      "0.398  0.033  0.991  short_nouns_onomatopoeia         Man, Sim, Mat, Saf, Tem, Ham, Bet, Sum, Haw, Nav\n",
      "0.369  0.032  0.983  proper_nouns_places_ethnic       �, Canad, Gree, Jes, Dav, Mich, Tex, Kore, Chic, Naz\n",
      "0.432  0.043  0.977  acronyms_universities_agencies   NA, NA, AA, CN, NG, UC, NS, MIT, NC, IU\n",
      "0.482  0.051  0.976  common_verbs_actions             Can, Be, Go, Do, Read, Use, Are, Be, Don, Is\n",
      "0.391  0.034  0.975  abbreviations_acronyms_misc      Q, SA, PA, DA, EC, ST, PS, AD, CC, CD\n",
      "0.523  0.053  0.963  given_names_modern               Pat, David, Mark, Carol, Sam, Ken, Alex, Rob, Dan, Peter\n",
      "0.463  0.043  0.962  given_names_short_forms          jor, Ed, Rober, Jer, Ab, Hen, Franc, Scot, Ed, Jul\n",
      "0.428  0.044  0.959  institutional_process_terms      Ind, Eng, Cent, ploy, Wor, Intern, Stud, Ass, epend, reng\n",
      "0.408  0.043  0.933  surnames_place_based             Lee, Franklin, Lewis, ilton, Grant, Rand, Ford, Ross, Hamilton, Newton\n",
      "0.387  0.035  0.931  latin_roots_scientific_terms     stud, serv, vir, mov, Germ, Serv, Char, Mus, Vir, Sur\n",
      "0.523  0.072  0.928  international_organizations      UN, NASA, EPA, CDC, FDA, WHO, USDA, NASA, Antarctic, UNESCO\n",
      "0.447  0.044  0.911  generic_nouns_collections        things, questions, ideas, steps, items, topics, tips, lessons, Information, directions\n",
      "0.539  0.050  0.901  titles_honorifics_degrees        M, M, MS, Mr, MD, MS, MP, AM, SS, PM\n",
      "0.555  0.048  0.895  female_given_names_modern        Susan, leen, Barbara, Lisa, Laura, Karen, Jennifer, Nancy, Linda, nda\n",
      "0.469  0.055  0.892  ethnic_groups_regions_global     inese, Mexic, Chinese, Asian, Viet, Indones, Afghan, Turk, Ethiop, Tibet\n",
      "0.453  0.047  0.888  given_names_formal               John, William, James, George, Paul, Thomas, Robert, Louis, Jose, Charles\n",
      "0.457  0.048  0.878  name_prefixes_particles          �, �, �, �, de, le, cl, Th, St, qu\n",
      "0.420  0.043  0.841  adjectives_general_descriptors   new, main, common, New, early, proper, real, major, United, National\n",
      "0.551  0.055  0.831  gerunds_process_verbs            developing, Develop, improving, maintaining, ensuring, engaging, promoting, Building, addressing, achieving\n",
      "0.656  0.104  0.829  mesopotamia_ancient_near_east    Bas, mes, Mes, Bas, Babylon, bas, Assy, Mesopotam, Canaan, Mesopotamia\n",
      "0.574  0.066  0.827  nationalities_languages          English, British, European, French, German, Russ, anish, Germany, Greek, Spanish\n",
      "0.590  0.058  0.818  ethnic_conflict_groups           Croat, Rwanda, Yugoslav, celiac, Croatia, Bosnia, eliac, Kosovo, Croatian, ić\n",
      "0.480  0.055  0.814  female_given_names_titles        Mary, Ann, abeth, izabeth, Elizabeth, Mrs, Rose, Anne, Jane, Maria\n",
      "0.410  0.036  0.811  academic_historical_disciplines   �, �, Americ, scient, histor, Aust, Hist, philos, Medic, mathemat\n",
      "0.480  0.054  0.798  famous_people_figures            incoln, Lincoln, Obama, Trump, Jefferson, nedy, Hitler, Darwin, osevelt, Bush\n",
      "0.520  0.057  0.785  cities_states_places             York, iforn, California, ashington, Washington, Texas, ville, burg, Florida, Virginia\n",
      "0.574  0.067  0.783  uk_aus_places_regions            ondon, ford, London, Scotland, hire, Oxford, Kent, hester, Wales, Cambridge\n",
      "0.486  0.052  0.772  ancient_historical_figures       ius, usalem, Moses, Romans, Greeks, Genesis, Columbus, BCE, Athens, Solomon\n",
      "0.633  0.080  0.760  religions_islam_judaism          Jewish, Jews, Arab, Muslim, Islam, Islamic, Muslims, Arabic, ammad, Allah\n",
      "0.438  0.050  0.752  technology_brands_internet       Google, COVID, Facebook, .gov, PDF, Amazon, Microsoft, Wikipedia, cyclopedia, Twitter\n",
      "0.547  0.071  0.744  countries_world_regions          world, country, urope, Europe, US, countries, World, America, Earth, society\n",
      "0.443  0.041  0.727  latin_prefixes_processes         �, �, comp, imp, comm, diff, cons, acc, prov, reg\n",
      "0.523  0.057  0.717  institutions_organizations       University, government, education, business, .com, industry, company, schools, ournal, School\n",
      "0.551  0.071  0.709  south_asia_india_culture         Indian, akistan, Hindu, Java, Bh, indo, apore, Sri, Bangladesh, Delhi\n",
      "0.434  0.052  0.673  syllables_interjections          ha, ra, sa, ke, ma, Su, �, Me, fa, Ju\n",
      "0.898  0.011  0.667  milk                             milk, Milk, Milk\n",
      "0.902  0.021  0.667  internet                         Internet, internet, Internet\n",
      "0.471  0.049  0.644  surnames_family_names            ohn, ley, augh, erson, son, berg, ston, Smith, inson, stein\n",
      "0.512  0.055  0.629  historical_religious_adjectives   American, ancient, Christian, Roman, Latin, Catholic, ieval, classical, royal, medieval\n",
      "0.621  0.078  0.622  prepositions_function_words      of, in, to, for, on, with, by, at, from, In\n",
      "0.490  0.039  0.619  name_fragments_foreign           �, esc, adel, Fern, Esc, �, abl, �, Bes, Blanc\n",
      "0.547  0.060  0.563  discourse_adverbs                again, However, later, especially, however, really, already, rather, actually, almost\n",
      "0.461  0.054  0.523  astronomy_disasters_events       Mars, moon, volcan, Moon, earthquake, urricane, meteor, ocaust, upiter, Jupiter\n",
      "0.902  0.002  0.500  None                             dates, Dates\n",
      "0.922  0.002  0.500  None                             wooden, Wooden\n",
      "0.914  0.000  0.500  None                             persistent, Persistent\n",
      "0.918  0.002  0.500  None                             tunnel, Tunnel\n",
      "0.922  0.002  0.500  None                             beef, Beef\n",
      "0.914  0.000  0.500  None                             cruise, Cruise\n",
      "0.895  0.000  0.500  None                             Franç, franç\n",
      "0.594  0.073  0.491  None                             not, any, no, every, any, few, non, little, never, either\n",
      "0.451  0.045  0.487  None                             ness, energy, temper, knowledge, mind, self, behavior, love, attention, respect\n",
      "0.512  0.068  0.451  None                             year, day, day, month, today, days, ember, week, months, May\n",
      "0.613  0.063  0.446  None                             create, created, identify, select, determine, creating, choose, identified, remove, determined\n",
      "0.680  0.099  0.439  None                             meditation, yoga, yog, mindfulness, relaxation, fasting, workout, mindful, Yoga, massage\n",
      "0.594  0.073  0.420  None                             ball, ball, sports, sport, athletes, football, Ball, Olympic, baseball, Sports\n",
      "0.551  0.055  0.414  None                             py, Py, croc, oxy, Ruby, Py, epoxy, pyro, chrys, Croc\n",
      "0.867  0.035  0.400  None                             apply, applying, applies, Apply, Apply\n",
      "0.520  0.061  0.397  None                             child, children, women, family, young, parent, adult, parents, kids, sex\n",
      "0.602  0.061  0.394  None                             ism, cult, history, tradition, culture, theory, History, stories, belief, literature\n",
      "0.490  0.050  0.389  None                             human, public, social, natural, physical, medical, global, national, chemical, economic\n",
      "0.578  0.071  0.383  None                             fossil, osaur, osaurs, extinct, fossils, asteroid, dinosaurs, geological, ocene, limestone\n",
      "0.598  0.067  0.382  None                             planet, star, Space, stars, astron, sky, universe, physics, Ast, planets\n",
      "0.455  0.051  0.369  None                             God, death, Christ, Jew, demon, King, irit, Jesus, king, spirit\n",
      "0.652  0.076  0.368  None                             often, usually, always, sometimes, generally, typically, commonly, frequently, mostly, mainly\n",
      "0.594  0.061  0.364  None                             outh, South, North, estern, outhern, West, orthern, north, south, East\n",
      "0.570  0.070  0.363  None                             red, white, black, green, Red, gold, blue, Black, Green, yellow\n",
      "0.484  0.055  0.358  None                             viron, govern, conom, polit, polic, offic, ivil, relig, ublic, ricult\n",
      "0.480  0.058  0.336  None                             sea, cean, River, coast, rock, river, stream, flood, ocean, sand\n",
      "0.535  0.063  0.336  None                             land, area, areas, States, local, community, population, city, states, region\n",
      "0.867  0.010  0.333  None                             skin, Skin, skin\n",
      "0.590  0.075  0.333  None                             Dr, medic, doctor, ospital, surgery, hospital, Medical, dental, Dr, doctors\n",
      "0.891  0.032  0.333  None                             protocol, protocols, Protocol\n",
      "0.883  0.027  0.333  None                             availability, availability, Availability\n",
      "0.852  0.007  0.333  None                             blank, Blank, blank\n",
      "0.879  0.024  0.333  None                             telephone, telephones, Telephone\n",
      "0.895  0.038  0.333  None                             counselor, counselors, Counselor\n",
      "0.883  0.003  0.333  None                             lamydia, chlamydia, Chlamydia\n",
      "0.473  0.046  0.332  None                             low, high, long, ollow, good, small, large, direct, better, low\n",
      "0.551  0.065  0.330  None                             useum, ibrary, Church, church, Court, Bible, pray, Holy, temple, Christians\n",
      "0.504  0.063  0.327  None                             health, ology, science, Health, Science, therapy, nutrition, medicine, iology, math\n",
      "0.602  0.086  0.327  None                             ail, books, leaves, email, letter, ears, ails, letters, papers, words\n",
      "0.498  0.055  0.321  None                             app, comput, computer, software, website, Web, files, computers, download, database\n",
      "0.656  0.080  0.318  None                             lor, cycl, chlor, fluor, cycl, chlorine, chlor, Cycl, Chlor, brom\n",
      "0.578  0.065  0.318  None                             ograph, phot, vide, image, ography, video, images, visual, picture, graph\n",
      "0.559  0.060  0.312  None                             food, drug, gas, drink, sugar, cohol, fuel, drugs, alcohol, Food\n",
      "0.492  0.059  0.309  None                             arch, wall, buildings, Arch, stone, fort, walls, bridge, Fort, stones\n",
      "0.590  0.059  0.307  None                             design, nature, pattern, structure, shape, properties, patterns, style, structures, ructure\n",
      "0.543  0.058  0.304  None                             mob, revolution, ocracy, politics, Revolution, slavery, democracy, racism, elections, protest\n",
      "0.459  0.053  0.296  None                             solar, nucle, nuclear, radiation, radio, frequency, nan, electron, noise, magnetic\n",
      "0.594  0.059  0.295  None                             mat, page, pack, piece, box, pages, pieces, plate, sheet, panel\n",
      "0.494  0.054  0.295  None                             animals, bat, dog, cat, animal, pet, birds, rat, dogs, bird\n",
      "0.652  0.079  0.293  None                             loss, fail, lack, lost, miss, Miss, lose, failed, forget, missing\n",
      "0.574  0.061  0.286  None                             water, air, climate, wind, heat, temperature, carbon, warm, hot, cold\n",
      "0.516  0.051  0.282  None                             part, sub, group, groups, parts, artment, series, Department, Part, section\n",
      "0.512  0.058  0.277  None                             language, words, word, speech, languages, anguage, sentence, ictionary, abulary, Language\n",
      "0.617  0.069  0.277  None                             safe, safety, security, protection, protected, secure, Security, Safety, protective, defense\n",
      "0.496  0.059  0.271  None                             nut, fig, egg, fruit, corn, vegetables, fruits, otton, rice, honey\n",
      "0.551  0.060  0.269  None                             land, plant, plants, soil, farm, veget, forest, wood, tree, trees\n",
      "0.547  0.064  0.268  None                             0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
      "0.551  0.067  0.265  None                             art, sing, music, Art, novel, song, poet, painting, Sing, arts\n",
      "0.559  0.061  0.265  None                             brain, sych, psych, nerve, neuro, Psych, nervous, zheimer, Alzheimer, autism\n",
      "0.498  0.049  0.264  None                             author, researchers, scientists, teacher, President, architect, ologist, ologists, experts, president\n",
      "0.617  0.083  0.262  None                             , !, \", ', (, *, +, ,, -, /\n",
      "0.625  0.065  0.260  None                             support, fund, supported, funding, supports, supporting, funds, Fund, funded, Support\n",
      "0.527  0.061  0.260  None                             exam, research, observ, analysis, poll, review, evalu, survey, assessment, discussion\n",
      "0.424  0.045  0.259  None                             article, essay, Journal, statement, lesson, message, articles, blog, advice, comment\n",
      "0.555  0.078  0.254  None                             less, increase, higher, lower, reduce, increased, increasing, greater, imum, limited\n",
      "0.875  0.020  0.250  None                             feminist, feminism, feminists, Feminism\n",
      "0.883  0.021  0.250  None                             rinse, rinsing, Rinse, rinsed\n",
      "0.457  0.039  0.236  None                             ation, ulation, development, ization, addition, treatment, olution, ruction, growth, production\n",
      "0.449  0.050  0.236  None                             import, $, pay, money, tax, labor, trade, emissions, price, income\n",
      "0.496  0.051  0.235  None                             people, students, person, others, men, patients, student, members, individuals, teachers\n",
      "0.562  0.057  0.227  None                             disease, species, cells, bacter, foods, virus, diseases, infection, bacteria, protein\n",
      "0.602  0.061  0.225  None                             d, nd, id, ld, ild, ind, ond, ids, iod, idd\n",
      "0.609  0.071  0.225  None                             quick, longer, slow, speed, quickly, fast, soon, rapid, easier, faster\n",
      "0.480  0.051  0.224  None                             ear, blood, leg, head, heart, Ear, feet, colon, eye, foot\n",
      "0.535  0.055  0.211  None                             electric, electricity, electrical, wire, battery, circuit, voltage, switch, copper, sensors\n",
      "0.527  0.060  0.210  None                             car, pot, bus, Car, engine, card, machine, vessel, ship, vehicle\n",
      "0.582  0.059  0.209  None                             war, studies, activities, activity, War, training, action, events, movement, attempt\n",
      "0.486  0.055  0.207  None                             ething, flu, abetes, itis, diabetes, ndrome, HIV, syndrome, obesity, ritis\n",
      "0.479  0.045  0.203  None                             anal, oral, ascular, ediatric, yroid, respiratory, ontal, cardiovascular, digestive, spinal\n",
      "0.535  0.062  0.200  None                             quest, travel, visit, walk, tour, hunt, journey, walking, swim, trip\n",
      "0.492  0.053  0.195  None                             dam, road, traffic, rail, concrete, mining, roads, grid, pit, mine\n",
      "0.715  0.098  0.194  None                             specific, unique, distinct, diverse, isolated, authentic, distinctive, intact, exclusive, singular\n",
      "0.559  0.059  0.190  None                             system, process, organ, environment, program, method, technology, systems, conditions, tool\n",
      "0.516  0.062  0.185  None                             fish, insect, fly, insects, fish, bees, tick, bee, salmon, Fish\n",
      "0.504  0.055  0.175  None                             pub, home, house, room, room, classroom, house, homes, bed, office\n",
      "0.594  0.065  0.174  None                             fit, adapt, adjust, suitable, orient, fit, adapted, suit, equipped, adaptation\n",
      "0.613  0.077  0.167  None                             worm, vomiting, parasites, worms, parasite, worm, mites, worms, lice, parasitic\n",
      "0.479  0.045  0.165  None                             acid, rogen, iron, oxygen, vitamin, oxide, olesterol, ulin, cholesterol, calcium\n",
      "0.543  0.056  0.160  None                             oil, tar, fluid, dust, oils, sediment, rubber, mud, Oil, dirt\n",
      "0.436  0.036  0.154  None                             ning, ating, uring, ting, aking, iving, ving, ering, ording, ining\n",
      "0.494  0.052  0.152  None                             different, individual, particular, various, similar, associated, related, relationship, previous, relative\n",
      "0.637  0.100  0.143  None                             cancer, Cancer, cancers, carcin, estrogen, malignant, cancerous, carcinoma, -cancer, otoxic\n",
      "0.439  0.039  0.139  None                             based, published, built, designed, written, located, named, treated, defined, covered\n",
      "0.471  0.046  0.133  None                             pop, run, turn, comb, dig, cut, lay, break, eat, draw\n",
      "0.508  0.056  0.126  None                             lit, light, sun, light, color, dark, bright, colors, colour, Color\n",
      "0.531  0.051  0.126  None                             important, interest, impact, success, results, future, ways, changes, symptoms, types\n",
      "0.463  0.052  0.126  None                             %, cent, percent, million, liter, hours, minutes, miles, billion, degrees\n",
      "0.504  0.058  0.118  None                             rest, leep, living, sleep, nest, refuge, sitting, sleeping, landing, Sleep\n",
      "0.688  0.079  0.115  None                             parallel, respectively, simultaneously, separately, versa, alternating, simultaneous, allel, sequential, interchangeably\n",
      "0.459  0.046  0.112  None                             effective, positive, critical, negative, responsible, efficient, dangerous, sustainable, toxic, harmful\n",
      "0.527  0.054  0.102  None                             re, res, rec, rel, rep, rese, rem, resp, ref, requ\n",
      "0.482  0.047  0.098  None                             pain, problems, damage, threat, harm, ror, situation, illness, depression, disorder\n",
      "0.379  0.068  0.096  None                             , �, �, �, researc, htt, citiz, destro, porary, conclud\n",
      "0.543  0.065  0.095  None                             attract, encourage, forced, prompt, influenced, trigger, encouraged, inspired, driven, incent\n",
      "0.527  0.058  0.094  None                             size, ength, length, strength, distance, square, height, ages, depth, sides\n",
      "0.396  0.035  0.093  None                             �, �, �, �, �, �, �, proble, indust, cir\n",
      "0.445  0.048  0.091  None                             webs, pen, glass, doll, paint, abric, fabric, bread, butter, clothing\n",
      "0.527  0.062  0.089  None                             possible, certain, likely, suggest, expect, hope, expected, discovered, predict, suggests\n",
      "0.432  0.043  0.086  None                             U, X, `, j, q, u, v, w, �, �\n",
      "0.479  0.047  0.084  None                             fall, mess, rout, rise, drop, storm, hop, flex, boost, decline\n",
      "0.385  0.042  0.083  None                             vertical, linear, indirect, horizontal, partial, circular, marginal, static, median, lateral\n",
      "0.451  0.046  0.075  None                             cap, mill, motor, bow, dial, pump, handle, ax, rig, pin\n",
      "0.463  0.040  0.075  None                             osph, electro, ohyd, phosph, hydro, amino, electrom, electroly, renal, raulic\n",
      "0.551  0.064  0.074  None                             taste, smell, herb, flavor, herbs, odor, herbal, vinegar, sauce, spices\n",
      "0.594  0.063  0.072  None                             fun, great, significant, extreme, interesting, powerful, huge, famous, beautiful, wonder\n",
      "0.598  0.064  0.071  None                             occup, inhabit, colonial, occupied, ruled, invasion, occupation, dominated, infest, inhabited\n",
      "0.559  0.059  0.070  None                             regard, accept, recommend, favor, recommended, prefer, promote, ideal, accepted, orses\n",
      "0.500  0.054  0.070  None                             born, seed, eggs, bud, pup, chick, breeding, breed, prey, hybrid\n",
      "0.520  0.046  0.069  None                             ated, ized, ished, ified, ised, complete, developed, rated, ulate, ulated\n",
      "0.459  0.041  0.064  None                             redu, activ, sever, econom, deg, situ, prote, disord, separ, integ\n",
      "0.500  0.051  0.061  None                             ability, iency, efficiency, esity, existence, diversity, lifestyle, independence, itivity, accuracy\n",
      "0.389  0.036  0.053  None                             olog, lud, velop, vern, ivid, acter, raph, creat, urop, struct\n",
      "0.527  0.061  0.052  None                             prevent, avoid, anti, counter, ban, resist, restrict, reject, preventing, escape\n",
      "0.508  0.058  0.052  None                             symbol, phrase, symbols, symptom, icon, symbolic, prototype, metaphor, iconic, stereotypes\n",
      "0.598  0.068  0.051  None                             E, Y, a, b, c, e, f, g, h, i\n",
      "0.461  0.049  0.044  None                             ill, aware, affected, wrong, interested, killed, infected, concerned, sick, unknown\n",
      "0.516  0.056  0.043  None                             profess, mention, saying, mentioned, stated, repeated, remark, announced, declared, remind\n",
      "0.605  0.069  0.041  None                             stop, block, blocks, delay, disrupt, stopped, barriers, impair, barrier, disturb\n",
      "0.500  0.052  0.037  None                             tissue, lymph, membrane, oste, muc, crust, clot, ilage, pulp, ocytes\n",
      "0.473  0.054  0.036  None                             un, inv, det, dise, impro, imm, unt, obs, abs, dest\n",
      "0.453  0.035  0.032  None                             ally, ily, ually, ically, ially, ently, ably, ately, ecially, ply\n",
      "0.432  0.048  0.031  None                             #, $, &, <, @, [, \\, ^, }, ~\n",
      "0.480  0.052  0.030  None                             released, removed, destroy, digest, renew, replaced, relax, drain, destroyed, recover\n",
      "0.185  0.031  0.029  None                             \u0000, \u0001, \u0002, \u0003, \u0004, \u0005, \u0006, \u0007,, \n",
      "0.432  0.040  0.028  None                             ia, ree, ange, ata, ody, io, ale, ee, ina, ane\n",
      "0.402  0.039  0.026  None                             wh, wor, whe, tw, fe, sm, bu, gra, sk, cre\n",
      "0.455  0.051  0.023  None                             ther, ater, ors, nder, vers, irst, fter, ower, ists, cer\n",
      "0.512  0.051  0.022  None                             inform, understand, improve, discuss, assess, reflect, surround, izes, connect, described\n",
      "0.443  0.036  0.022  None                             �, �, �, �, bec, includ, produ, differe, att, lear\n",
      "0.475  0.046  0.019  None                             ed, ight, red, able, hed, ced, ased, ible, wn, ied\n",
      "0.430  0.044  0.019  None                             necessary, essential, serious, useful, exact, successful, vital, practical, obvious, extensive\n",
      "0.605  0.064  0.017  None                             is, be, are, can, was, have, will, has, do, were\n",
      "0.471  0.045  0.016  None                             ies, ity, ions, ould, ations, ence, ents, ance, ress, ition\n",
      "0.436  0.042  0.014  None                             frozen, flowing, floating, packed, scattered, locked, rocky, rotating, curved, urved\n",
      "0.471  0.050  0.010  None                             elect, present, avail, perform, available, represent, employ, collect, required, produce\n",
      "0.379  0.035  0.008  None                             �, �, �, �, �, �, �, �, �, �\n",
      "0.467  0.048  0.007  None                             sit, occur, invest, exist, opt, react, interact, sat, consist, respond\n",
      "0.432  0.041  0.007  None                             ive, ial, ical, ous, ual, ific, ious, ular, ational, ative\n",
      "0.520  0.058  0.007  None                             B, C, D, F, G, H, J, K, L, N\n",
      "0.350  0.030  0.005  None                             ople, ween, iron, omen, reen, gin, ledge, chie, oura, ison\n",
      "0.393  0.037  0.004  None                             pro, con, ex, su, com, ne, se, en, ab, im\n",
      "0.770  0.108  0.000  None                             , ), ., ., ?, )., ),, :, .”, )\n",
      "0.516  0.064  0.000  None                             t, s, o, c, w, p, b, f, m, d\n",
      "0.523  0.052  0.000  None                             as, if, and, all, so, are, very, one, now, we\n",
      "0.445  0.042  0.000  None                             �, -st, -le, -th, -re, -sp, -se, -sh, -sc, -cent\n",
      "0.408  0.038  0.000  None                             out, ount, rough, ject, stem, ffect, round, own, chool, form\n",
      "0.477  0.049  0.000  None                             man, work, time, act, years, form, way, effect, count, sign\n",
      "0.621  0.068  0.000  None                             “, \", “, ‘, ', “The, ‘, “We, \"The, “I\n",
      "0.867  0.007  0.000  None                             ify, ifying, ifies\n",
      "0.898  0.000  0.000  None                             keep, keep\n",
      "0.930  0.000  0.000  None                             protect, protecting\n",
      "0.461  0.038  0.000  None                             -based, -related, -like, -old, -free, -known, -called, -making, -shaped, -friendly\n",
      "0.898  0.000  0.000  None                             believe, believe\n",
      "0.408  0.036  0.000  None                             -term, -year, -up, -time, -level, -scale, -century, -off, -American, -quality\n",
      "1.000  0.000  0.000  None                             igation\n",
      "0.996  0.000  0.000  None                             pharm\n",
      "0.883  0.020  0.000  None                             align, aligned, aligns, aligning\n",
      "0.883  0.000  0.000  None                             action, actions\n",
      "0.898  0.000  0.000  None                             impairment, impairments\n",
      "0.996  0.000  0.000  None                             othy\n",
      "1.000  0.000  0.000  None                             uncon\n",
      "0.996  0.000  0.000  None                             sealed\n",
      "1.000  0.000  0.000  None                             م\n",
      "1.000  0.000  0.000  None                             help\n",
      "1.008  0.000  0.000  None                             reliance\n",
      "0.898  0.030  0.000  None                             teaspoon, tablespoon, tablespoons\n",
      "0.906  0.000  0.000  None                             creek, creeks\n",
      "0.996  0.000  0.000  None                             rug\n",
      "1.000  0.000  0.000  None                             fibrous\n",
      "0.891  0.011  0.000  None                             coincide, coincided, coincides\n",
      "0.895  0.000  0.000  None                             lengthen, lengthening\n",
      "0.906  0.002  0.000  None                             creditors, creditor\n",
      "1.000  0.000  0.000  None                             sul\n",
      "1.008  0.000  0.000  None                             gynec\n",
      "1.008  0.000  0.000  None                             stats\n",
      "1.000  0.000  0.000  None                             -reliance\n",
      "1.000  0.000  0.000  None                             whirl\n",
      "1.000  0.000  0.000  None                             apprehension\n",
      "1.000  0.000  0.000  None                             cyt\n",
      "1.000  0.000  0.000  None                             inflatable\n",
      "1.000  0.000  0.000  None                             catalogued\n",
      "1.008  0.000  0.000  None                             biped\n",
      "1.008  0.000  0.000  None                             teral\n",
      "0.996  0.000  0.000  None                             imono\n",
      "1.000  0.000  0.000  None                             dot\n",
      "1.000  0.000  0.000  None                             verses\n",
      "0.996  0.000  0.000  None                             quill\n"
     ]
    }
   ],
   "source": [
    "for reference_group in reference_groups:\n",
    "    cos_max = reference_group[\"cluster_quality\"][\"cos_max\"]\n",
    "    cos_std = reference_group[\"cluster_quality\"][\"cos_std\"]\n",
    "    title = str(reference_group[\"title\"])\n",
    "    tokens = reference_group[\"tokens\"]\n",
    "    pct_start_upper = reference_group[\"pct_start_upper\"]\n",
    "    \n",
    "    print(f\"{cos_max:0.3f}  {cos_std:0.3f}  {pct_start_upper:0.3f}  {title:<30}   {', '.join([str(v) for v in tokens[0:10]])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7acfb4a9-8a75-4026-a34e-7abc7324d73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.887   0.000   surname_singleton                Hart, Hart\n",
      "0.523   0.053   given_names_modern               Pat, David, Mark, Carol, Sam, Ken, Alex, Rob, Dan, Peter\n",
      "0.463   0.043   given_names_short_forms          jor, Ed, Rober, Jer, Ab, Hen, Franc, Scot, Ed, Jul\n",
      "0.408   0.043   surnames_place_based             Lee, Franklin, Lewis, ilton, Grant, Rand, Ford, Ross, Hamilton, Newton\n",
      "0.555   0.048   female_given_names_modern        Susan, leen, Barbara, Lisa, Laura, Karen, Jennifer, Nancy, Linda, nda\n",
      "0.453   0.047   given_names_formal               John, William, James, George, Paul, Thomas, Robert, Louis, Jose, Charles\n",
      "0.457   0.048   name_prefixes_particles          �, �, �, �, de, le, cl, Th, St, qu\n",
      "0.480   0.055   female_given_names_titles        Mary, Ann, abeth, izabeth, Elizabeth, Mrs, Rose, Anne, Jane, Maria\n",
      "0.471   0.049   surnames_family_names            ohn, ley, augh, erson, son, berg, ston, Smith, inson, stein\n",
      "0.490   0.039   name_fragments_foreign           �, esc, adel, Fern, Esc, �, abl, �, Bes, Blanc\n"
     ]
    }
   ],
   "source": [
    "for reference_group in reference_groups:\n",
    "    cos_max = reference_group[\"cluster_quality\"][\"cos_max\"]\n",
    "    cos_std = reference_group[\"cluster_quality\"][\"cos_std\"]\n",
    "    title = str(reference_group[\"title\"])\n",
    "    tokens = reference_group[\"tokens\"]\n",
    "    if 'name' in title:        \n",
    "        print(f\"{cos_max:0.3f}   {cos_std:0.3f}   {title:<30}   {', '.join(tokens[0:10])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb5db2-9611-448e-9dd4-44514420a387",
   "metadata": {},
   "source": [
    "# Token Cluster Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3ad277d5-c6d3-4b55-bb11-79aee632c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_cluster_map(clusters):\n",
    "    inv = {}\n",
    "    for k, vs in clusters.items():\n",
    "        for v in vs:\n",
    "            inv[v] = int(k)\n",
    "    return inv\n",
    "\n",
    "token_cluster_map = get_token_cluster_map(clusters)\n",
    "\n",
    "cluster_lookup = {c[\"cluster_id\"]: c for c in reference_groups}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bc0bb214-da54-4170-8148-8b29f057f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def iter_parquet_text(glob_pattern: str, field: str = \"text\"):\n",
    "    for path in glob(glob_pattern):\n",
    "        table = pq.read_table(path, columns=[field])\n",
    "        for value in table[field].to_pylist():\n",
    "            if value is not None:\n",
    "                yield value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "808cc41d-9412-4887-a30b-3a3efc58debb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shard_00000.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../../data/fineweb-edu-100b-shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7f75e519-458b-4617-a4c3-3126ed069795",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in enumerate(iter_parquet_text(\"../../../../data/fineweb-edu-100b-shuffle/*.parquet\")):\n",
    "    sample_text =  text\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2b3eae70-66a5-454f-98b4-86ff4a0311aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58      465     None                             , !, \", ', (, *, +, ,, -, /\n",
      "193     214     prepositions_function_words      of, in, to, for, on, with, by, at, from, In\n",
      "95      145     None                             is, be, are, can, was, have, will, has, do, were\n",
      "127     95      None                             , ), ., ., ?, )., ),, :, .”, )\n",
      "131     84      None                             0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
      "11      74      None                             man, work, time, act, years, form, way, effect, count, sign\n",
      "27      42      None                             ation, ulation, development, ization, addition, treatment, olution, ruction, growth, production\n",
      "137     40      None                             important, interest, impact, success, results, future, ways, changes, symptoms, types\n",
      "220     35      None                             dam, road, traffic, rail, concrete, mining, roads, grid, pit, mine\n",
      "155     34      None                             import, $, pay, money, tax, labor, trade, emissions, price, income\n",
      "55      29      None                             car, pot, bus, Car, engine, card, machine, vessel, ship, vehicle\n",
      "35      28      None                             system, process, organ, environment, program, method, technology, systems, conditions, tool\n",
      "151     25      None                             less, increase, higher, lower, reduce, increased, increasing, greater, imum, limited\n",
      "235     22      None                             %, cent, percent, million, liter, hours, minutes, miles, billion, degrees\n",
      "86      22      None                             water, air, climate, wind, heat, temperature, carbon, warm, hot, cold\n",
      "146     22      countries_world_regions          world, country, urope, Europe, US, countries, World, America, Earth, society\n",
      "79      18      None                             low, high, long, ollow, good, small, large, direct, better, low\n",
      "172     16      adjectives_general_descriptors   new, main, common, New, early, proper, real, major, United, National\n",
      "174     15      None                             U, X, `, j, q, u, v, w, �, �\n",
      "38      15      None                             elect, present, avail, perform, available, represent, employ, collect, required, produce\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "sample_text_clusters = [token_cluster_map[idx] for idx in tokenizer.encode_ordinary(sample_text)]\n",
    "\n",
    "for cluster_id, count in Counter(sample_text_clusters).most_common(20):\n",
    "    reference_group = cluster_lookup[cluster_id]\n",
    "    title = str(reference_group[\"title\"])\n",
    "    tokens = reference_group[\"tokens\"]\n",
    "    \n",
    "    print(f\"{cluster_id:<5}   {count:<5}   {title:<30}   {', '.join([str(v) for v in tokens[0:10]])}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eff826ae-effa-41a3-8810-147cbce89c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "cluster_count = Counter()\n",
    "prev_pair_count = {c: Counter() for c in cluster_lookup.keys()}\n",
    "next_pair_count = {c: Counter() for c in cluster_lookup.keys()}\n",
    "\n",
    "total = 0\n",
    "\n",
    "for text in iter_parquet_text(\"../../../../data/fineweb-edu-100b-shuffle/*.parquet\"):\n",
    "    ids = tokenizer.encode_ordinary(text)\n",
    "    clusters = [token_cluster_map[i] for i in ids]\n",
    "\n",
    "    for j, c in enumerate(clusters):\n",
    "        cluster_count[c] += 1\n",
    "\n",
    "        if j > 0:\n",
    "            prev_pair_count[c][clusters[j - 1]] += 1\n",
    "        if j < len(clusters) - 1:\n",
    "            next_pair_count[c][clusters[j + 1]] += 1\n",
    "\n",
    "        total += 1\n",
    "        if total >= 1_000_000:\n",
    "            break\n",
    "    if total >= 1_000_000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1f1b7140-f5d5-4e84-b640-14cafc6adb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201     4482         name_prefixes_particles          �, �, �, �, de, le, cl, Th, St, qu\n",
      "   58      1469         None                             , !, \", ', (, *, +, ,, -, /\n",
      "   127     810          None                             , ), ., ., ?, )., ),, :, .”, )\n",
      "   193     529          prepositions_function_words      of, in, to, for, on, with, by, at, from, In\n",
      "\n",
      "   174     900          None                             U, X, `, j, q, u, v, w, �, �\n",
      "   114     529          None                             E, Y, a, b, c, e, f, g, h, i\n",
      "   187     286          None                             ople, ween, iron, omen, reen, gin, ledge, chie, oura, ison\n",
      "----------------------------------------------------------------------------------------------------\n",
      "4       2113         surnames_family_names            ohn, ley, augh, erson, son, berg, ston, Smith, inson, stein\n",
      "   58      547          None                             , !, \", ', (, *, +, ,, -, /\n",
      "   127     251          None                             , ), ., ., ?, )., ),, :, .”, )\n",
      "   193     136          prepositions_function_words      of, in, to, for, on, with, by, at, from, In\n",
      "\n",
      "   58      1006         None                             , !, \", ', (, *, +, ,, -, /\n",
      "   95      220          None                             is, be, are, can, was, have, will, has, do, were\n",
      "   127     154          None                             , ), ., ., ?, )., ),, :, .”, )\n",
      "----------------------------------------------------------------------------------------------------\n",
      "36      1663         given_names_formal               John, William, James, George, Paul, Thomas, Robert, Louis, Jose, Charles\n",
      "   58      493          None                             , !, \", ', (, *, +, ,, -, /\n",
      "   193     276          prepositions_function_words      of, in, to, for, on, with, by, at, from, In\n",
      "   127     251          None                             , ), ., ., ?, )., ),, :, .”, )\n",
      "\n",
      "   58      303          None                             , !, \", ', (, *, +, ,, -, /\n",
      "   50      142          None                             B, C, D, F, G, H, J, K, L, N\n",
      "   4       117          surnames_family_names            ohn, ley, augh, erson, son, berg, ston, Smith, inson, stein\n",
      "----------------------------------------------------------------------------------------------------\n",
      "128     1086         given_names_modern               Pat, David, Mark, Carol, Sam, Ken, Alex, Rob, Dan, Peter\n",
      "   58      353          None                             , !, \", ', (, *, +, ,, -, /\n",
      "   127     191          None                             , ), ., ., ?, )., ),, :, .”, )\n",
      "   193     184          prepositions_function_words      of, in, to, for, on, with, by, at, from, In\n",
      "\n",
      "   58      208          None                             , !, \", ', (, *, +, ,, -, /\n",
      "   187     97           None                             ople, ween, iron, omen, reen, gin, ledge, chie, oura, ison\n",
      "   4       93           surnames_family_names            ohn, ley, augh, erson, son, berg, ston, Smith, inson, stein\n",
      "----------------------------------------------------------------------------------------------------\n",
      "93      1008         surnames_place_based             Lee, Franklin, Lewis, ilton, Grant, Rand, Ford, Ross, Hamilton, Newton\n",
      "   58      354          None                             , !, \", ', (, *, +, ,, -, /\n",
      "   193     144          prepositions_function_words      of, in, to, for, on, with, by, at, from, In\n",
      "   127     118          None                             , ), ., ., ?, )., ),, :, .”, )\n",
      "\n",
      "   58      378          None                             , !, \", ', (, *, +, ,, -, /\n",
      "   95      83           None                             is, be, are, can, was, have, will, has, do, were\n",
      "   127     72           None                             , ), ., ., ?, )., ),, :, .”, )\n",
      "----------------------------------------------------------------------------------------------------\n",
      "185     453          female_given_names_titles        Mary, Ann, abeth, izabeth, Elizabeth, Mrs, Rose, Anne, Jane, Maria\n",
      "   58      145          None                             , !, \", ', (, *, +, ,, -, /\n",
      "   193     88           prepositions_function_words      of, in, to, for, on, with, by, at, from, In\n",
      "   127     59           None                             , ), ., ., ?, )., ),, :, .”, )\n",
      "\n",
      "   58      104          None                             , !, \", ', (, *, +, ,, -, /\n",
      "   127     42           None                             , ), ., ., ?, )., ),, :, .”, )\n",
      "   95      31           None                             is, be, are, can, was, have, will, has, do, were\n",
      "----------------------------------------------------------------------------------------------------\n",
      "32      390          given_names_short_forms          jor, Ed, Rober, Jer, Ab, Hen, Franc, Scot, Ed, Jul\n",
      "   127     136          None                             , ), ., ., ?, )., ),, :, .”, )\n",
      "   58      119          None                             , !, \", ', (, *, +, ,, -, /\n",
      "   193     22           prepositions_function_words      of, in, to, for, on, with, by, at, from, In\n",
      "\n",
      "   174     103          None                             U, X, `, j, q, u, v, w, �, �\n",
      "   114     62           None                             E, Y, a, b, c, e, f, g, h, i\n",
      "   187     35           None                             ople, ween, iron, omen, reen, gin, ledge, chie, oura, ison\n",
      "----------------------------------------------------------------------------------------------------\n",
      "157     141          female_given_names_modern        Susan, leen, Barbara, Lisa, Laura, Karen, Jennifer, Nancy, Linda, nda\n",
      "   58      49           None                             , !, \", ', (, *, +, ,, -, /\n",
      "   193     21           prepositions_function_words      of, in, to, for, on, with, by, at, from, In\n",
      "   127     15           None                             , ), ., ., ?, )., ),, :, .”, )\n",
      "\n",
      "   50      19           None                             B, C, D, F, G, H, J, K, L, N\n",
      "   58      15           None                             , !, \", ', (, *, +, ,, -, /\n",
      "   4       15           surnames_family_names            ohn, ley, augh, erson, son, berg, ston, Smith, inson, stein\n",
      "----------------------------------------------------------------------------------------------------\n",
      "253     34           name_fragments_foreign           �, esc, adel, Fern, Esc, �, abl, �, Bes, Blanc\n",
      "   174     13           None                             U, X, `, j, q, u, v, w, �, �\n",
      "   127     5            None                             , ), ., ., ?, )., ),, :, .”, )\n",
      "   165     5            latin_roots_scientific_terms     stud, serv, vir, mov, Germ, Serv, Char, Mus, Vir, Sur\n",
      "\n",
      "   174     15           None                             U, X, `, j, q, u, v, w, �, �\n",
      "   114     5            None                             E, Y, a, b, c, e, f, g, h, i\n",
      "   87      5            None                             ia, ree, ange, ata, ody, io, ale, ee, ina, ane\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for cluster_id, count in Counter(token_cluster_counts).most_common():\n",
    "    reference_group = cluster_lookup[cluster_id]\n",
    "    if reference_group[\"probable_reference\"]:\n",
    "        title = str(reference_group[\"title\"])\n",
    "        if not \"name\" in title:\n",
    "            continue\n",
    "        tokens = reference_group[\"tokens\"]\n",
    "        \n",
    "        print(f\"{cluster_id:<5}   {count:<10}   {title:<30}   {', '.join([str(v) for v in tokens[0:10]])}\")\n",
    "        for prev_cluster_id, prev_count in prev_pair_count[cluster_id].most_common(3):\n",
    "            prev_reference_group = cluster_lookup[prev_cluster_id]\n",
    "            prev_title = str(prev_reference_group[\"title\"])\n",
    "            prev_tokens = prev_reference_group[\"tokens\"]\n",
    "            print(f\"   {prev_cluster_id:<5}   {prev_count:<10}   {prev_title:<30}   {', '.join([str(v) for v in prev_tokens[0:10]])}\")\n",
    "        print()\n",
    "        for next_cluster_id, next_count in next_pair_count[cluster_id].most_common(3):\n",
    "            next_reference_group = cluster_lookup[next_cluster_id]\n",
    "            next_title = str(next_reference_group[\"title\"])\n",
    "            next_tokens = next_reference_group[\"tokens\"]\n",
    "            print(f\"   {next_cluster_id:<5}   {next_count:<10}   {next_title:<30}   {', '.join([str(v) for v in next_tokens[0:10]])}\")\n",
    "        print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943e1ae6-95bb-40ee-8e00-3376deb5c6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
